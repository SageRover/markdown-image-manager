#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Markdownå›¾ç‰‡ç®¡å®¶ - ä¿®å¤ç‰ˆæœ¬
åŠŸèƒ½ï¼š
1. æœç´¢MDæ–‡ä»¶å’Œå›¾ç‰‡ï¼Œåˆ†æå¼•ç”¨å…³ç³»
2. ä¸Šä¼ å›¾ç‰‡åˆ°å›¾åºŠï¼ˆé€šè¿‡PicListï¼‰
3. æ›¿æ¢å›¾ç‰‡é“¾æ¥ï¼ˆæœ¬åœ°/è¿œç¨‹ï¼‰
4. ä¸‹è½½è¿œç¨‹å›¾ç‰‡åˆ°æœ¬åœ°
5. åˆ é™¤æœªä½¿ç”¨çš„æœ¬åœ°å›¾ç‰‡
"""

import os
import re
import json
import shutil
import datetime
import shutil
import requests
import subprocess
from pathlib import Path
from urllib.parse import urlparse, unquote
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
from typing import Dict, List, Set, Tuple
import threading

class MarkdownImageManager:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Markdownå›¾ç‰‡ç®¡å®¶")
        self.root.geometry("1000x700")
        
        # æ•°æ®å­˜å‚¨
        self.workspace_path = ""
        self.md_files = []
        self.image_files = []
        self.image_references = {}  # {md_file: [image_paths]}
        self.unused_images = []
        self.invalid_images = {}  # {md_file: [invalid_image_paths]}
        self.image_mapping = {}  # {local_path: remote_url}
        self.mapping_file = "image_mapping.json"
        
        # åŠ è½½å¹¶è¿ç§»å›¾ç‰‡æ˜ å°„è¡¨
        self.load_image_mapping_with_migration()
        
        # ç»Ÿè®¡æ•°æ®
        self.referenced_local_images = []  # è¢«å¼•ç”¨çš„æœ¬åœ°å›¾ç‰‡
        self.remote_images = []  # è¿œç¨‹å›¾ç‰‡åˆ—è¡¨
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.svg'}
        
        self.setup_ui()
        self.load_mapping()
    
    def normalize_path(self, path):
        """ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§"""
        if not path:
            return path
        
        # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
        normalized = path.replace('\\\\', '/').replace('\\', '/')
        
        # å»é™¤é‡å¤çš„åˆ†éš”ç¬¦
        normalized = re.sub(r'/+', '/', normalized)
        
        # å»é™¤æœ«å°¾çš„åˆ†éš”ç¬¦ï¼ˆé™¤éæ˜¯æ ¹ç›®å½•æˆ–Windowsé©±åŠ¨å™¨æ ¹ç›®å½•ï¼‰
        if len(normalized) > 1 and normalized.endswith('/'):
            # ä¿ç•™Windowsé©±åŠ¨å™¨æ ¹ç›®å½•çš„æ–œæ  (å¦‚ D:/)
            if not (len(normalized) >= 3 and normalized[1:3] == ':/'):
                normalized = normalized.rstrip('/')
        
        return normalized

    def migrate_image_mapping(self):
        """è¿ç§»ç°æœ‰å›¾ç‰‡æ˜ å°„è¡¨ï¼Œä¿®å¤è·¯å¾„åˆ†éš”ç¬¦é—®é¢˜"""
        
        mapping_file = os.path.join(self.workspace_path, self.mapping_file)
        
        if not os.path.exists(mapping_file):
            return True
        
        try:
            # è¯»å–ç°æœ‰æ˜ å°„
            with open(mapping_file, 'r', encoding='utf-8') as f:
                original_mapping = json.load(f)
            
            if not original_mapping:
                return True
            
            # åˆ†ææ˜¯å¦éœ€è¦è¿ç§»
            needs_migration = False
            problematic_count = 0
            
            for local_path in original_mapping.keys():
                if '\\' in local_path and '/' in local_path:
                    needs_migration = True
                    problematic_count += 1
            
            if not needs_migration:
                return True
            
            # åˆ›å»ºå¤‡ä»½
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{mapping_file}.backup_{timestamp}"
            shutil.copy2(mapping_file, backup_file)
            
            # æ‰§è¡Œè¿ç§»
            new_mapping = {}
            normalized_count = 0
            
            for local_path, remote_url in original_mapping.items():
                normalized_path = self.normalize_path(local_path)
                
                if normalized_path != local_path:
                    normalized_count += 1
                
                # å¤„ç†é‡å¤é¡¹ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
                if normalized_path not in new_mapping:
                    new_mapping[normalized_path] = remote_url
            
            # ä¿å­˜æ–°æ˜ å°„
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump(new_mapping, f, ensure_ascii=False, indent=2)
            
            if normalized_count > 0:
                self.log(f"âœ… æ˜ å°„è¡¨è¿ç§»å®Œæˆ: è§„èŒƒåŒ–äº† {normalized_count} ä¸ªè·¯å¾„")
            
            return True
            
        except Exception as e:
            self.log(f"âŒ æ˜ å°„è¡¨è¿ç§»å¤±è´¥: {e}")
            return False

    def load_image_mapping_with_migration(self):
        """åŠ è½½å›¾ç‰‡æ˜ å°„è¡¨ï¼Œå¦‚æœéœ€è¦åˆ™è‡ªåŠ¨è¿ç§»"""
        
        # å…ˆå°è¯•è¿ç§»
        self.migrate_image_mapping()
        
        # ç„¶ååŠ è½½æ˜ å°„è¡¨
        mapping_file = os.path.join(self.workspace_path, self.mapping_file)
        
        if os.path.exists(mapping_file):
            try:
                with open(mapping_file, 'r', encoding='utf-8') as f:
                    self.image_mapping = json.load(f)
                
                # ç¡®ä¿æ‰€æœ‰è·¯å¾„éƒ½æ˜¯è§„èŒƒåŒ–çš„
                normalized_mapping = {}
                for local_path, remote_url in self.image_mapping.items():
                    normalized_path = self.normalize_path(local_path)
                    normalized_mapping[normalized_path] = remote_url
                
                self.image_mapping = normalized_mapping
                
            except Exception as e:
                self.log(f"âŒ åŠ è½½æ˜ å°„è¡¨å¤±è´¥: {e}")
                self.image_mapping = {}
        else:
            self.image_mapping = {}

    def save_image_mapping_normalized(self):
        """ä¿å­˜å›¾ç‰‡æ˜ å°„è¡¨ï¼Œç¡®ä¿æ‰€æœ‰è·¯å¾„éƒ½æ˜¯è§„èŒƒåŒ–çš„"""
        
        if not self.image_mapping:
            return
        
        # è§„èŒƒåŒ–æ‰€æœ‰è·¯å¾„
        normalized_mapping = {}
        for local_path, remote_url in self.image_mapping.items():
            normalized_path = self.normalize_path(local_path)
            normalized_mapping[normalized_path] = remote_url
        
        mapping_file = os.path.join(self.workspace_path, self.mapping_file)
        
        try:
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump(normalized_mapping, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°å†…å­˜ä¸­çš„æ˜ å°„
            self.image_mapping = normalized_mapping
            
        except Exception as e:
            self.log(f"âŒ ä¿å­˜æ˜ å°„è¡¨å¤±è´¥: {e}")

    def safe_relpath(self, path, start):
        """å®‰å…¨çš„ç›¸å¯¹è·¯å¾„è®¡ç®—ï¼Œå¤„ç†è·¨é©±åŠ¨å™¨æƒ…å†µ"""
        try:
            # å…ˆè§„èŒƒåŒ–è¾“å…¥è·¯å¾„
            path = self.normalize_path(path)
            start = self.normalize_path(start)
            
            rel_path = os.path.relpath(path, start)
            return self.normalize_path(rel_path)
        except ValueError:
            # è·¨é©±åŠ¨å™¨æƒ…å†µï¼Œè¿”å›è§„èŒƒåŒ–çš„ç»å¯¹è·¯å¾„
            return self.normalize_path(path)
    
    def download_image_with_retry(self, url, local_path, max_retries=1):
        """å›¾ç‰‡ä¸‹è½½ï¼Œå•æ¬¡å°è¯•"""
        import time
        
        # ä¸åŒçš„è¯·æ±‚å¤´é…ç½®
        headers_list = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Referer': 'https://gitee.com/',
                'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Cache-Control': 'no-cache',
            },
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
                'Accept': 'image/webp,*/*',
                'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            },
            {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
            }
        ]
        
        # å¤„ç†Gitee URLçš„ç‰¹æ®Šæƒ…å†µ
        original_url = url
        if 'gitee.com' in url and '//img/' in url:
            # ä¿®å¤åŒæ–œæ é—®é¢˜
            url = url.replace('//img/', '/img/')
            self.log(f"    ä¿®å¤Gitee URL: {url}")
        
        for attempt in range(max_retries):
            try:
                headers = headers_list[attempt % len(headers_list)]
                
                # åˆ›å»ºsessionä»¥ä¿æŒè¿æ¥
                session = requests.Session()
                session.headers.update(headers)
                
                self.log(f"    ä¸‹è½½: {os.path.basename(local_path)}")
                
                response = session.get(url, timeout=30, allow_redirects=True)
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 200:
                    # æ£€æŸ¥å†…å®¹ç±»å‹
                    content_type = response.headers.get('content-type', '').lower()
                    if 'image' in content_type or len(response.content) > 1000:
                        with open(local_path, 'wb') as f:
                            f.write(response.content)
                        return True
                    else:
                        self.log(f"    å“åº”ä¸æ˜¯å›¾ç‰‡å†…å®¹: {content_type}")
                elif response.status_code == 403:
                    self.log(f"    403 Forbidden - å°è¯•å…¶ä»–æ–¹æ³•")
                    # å¯¹äº403é”™è¯¯ï¼Œå°è¯•ä¸åŒçš„URLæ ¼å¼
                    if 'gitee.com' in url and attempt == 0:
                        # å°è¯•å»æ‰rawå‚æ•°
                        alt_url = url.replace('/raw/master/', '/master/')
                        try:
                            alt_response = session.get(alt_url, timeout=30)
                            if alt_response.status_code == 200:
                                with open(local_path, 'wb') as f:
                                    f.write(alt_response.content)
                                return True
                        except:
                            pass
                else:
                    self.log(f"    HTTP {response.status_code}: {response.reason}")
                
            except requests.exceptions.Timeout:
                self.log(f"    ä¸‹è½½è¶…æ—¶")
            except requests.exceptions.ConnectionError:
                self.log(f"    è¿æ¥é”™è¯¯")
            except Exception as e:
                self.log(f"    ä¸‹è½½é”™è¯¯: {str(e)}")
            
            # ä¸é‡è¯•ï¼Œç›´æ¥é€€å‡ºå¾ªç¯
            break
        
        return False
    
    def setup_ui(self):
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # å·¥ä½œç›®å½•é€‰æ‹©
        dir_frame = ttk.Frame(main_frame)
        dir_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(dir_frame, text="å·¥ä½œç›®å½•:").grid(row=0, column=0, sticky=tk.W)
        self.dir_var = tk.StringVar()
        self.dir_entry = ttk.Entry(dir_frame, textvariable=self.dir_var, width=60)
        self.dir_entry.grid(row=0, column=1, padx=(5, 5), sticky=(tk.W, tk.E))
        ttk.Button(dir_frame, text="é€‰æ‹©", command=self.select_directory).grid(row=0, column=2)
        
        dir_frame.columnconfigure(1, weight=1)
        
        # åŠŸèƒ½æŒ‰é’®åŒºåŸŸ
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # ç¬¬ä¸€è¡ŒæŒ‰é’®
        ttk.Button(button_frame, text="1. æ‰«æåˆ†æ", command=self.scan_files, width=15).grid(row=0, column=0, padx=2)
        ttk.Button(button_frame, text="2. ä¸Šä¼ åˆ°å›¾åºŠ", command=self.upload_images, width=15).grid(row=0, column=1, padx=2)
        ttk.Button(button_frame, text="3. æ›¿æ¢ä¸ºè¿œç¨‹", command=self.replace_to_remote, width=15).grid(row=0, column=2, padx=2)
        ttk.Button(button_frame, text="4. æ›¿æ¢ä¸ºæœ¬åœ°", command=self.replace_to_local, width=15).grid(row=0, column=3, padx=2)
        
        # ç¬¬äºŒè¡ŒæŒ‰é’®
        ttk.Button(button_frame, text="5. ä¸‹è½½è¿œç¨‹å›¾ç‰‡", command=self.download_images, width=15).grid(row=1, column=0, padx=2, pady=2)
        ttk.Button(button_frame, text="6. åˆ é™¤æœ¬åœ°å›¾ç‰‡", command=self.delete_local_images, width=15).grid(row=1, column=1, padx=2, pady=2)
        ttk.Button(button_frame, text="ä¿®å¤å¤±æ•ˆé“¾æ¥", command=self.fix_broken_links, width=15).grid(row=1, column=2, padx=2, pady=2)
        ttk.Button(button_frame, text="å¯¼å‡ºæŠ¥å‘Š", command=self.export_report, width=15).grid(row=1, column=3, padx=2, pady=2)
        
        # ç¬¬ä¸‰è¡ŒæŒ‰é’®
        ttk.Button(button_frame, text="æ™ºèƒ½ä¿®å¤è·¯å¾„", command=self.smart_fix_paths, width=15).grid(row=2, column=0, padx=2, pady=2)
        ttk.Button(button_frame, text="æ’¤é”€ä¿®å¤", command=self.undo_fixes, width=15).grid(row=2, column=1, padx=2, pady=2)
        ttk.Button(button_frame, text="æ¸…ç©ºæ—¥å¿—", command=self.clear_log, width=15).grid(row=2, column=2, padx=2, pady=2)
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        result_frame = ttk.Frame(main_frame)
        result_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        # åˆ›å»ºNotebookç”¨äºæ ‡ç­¾é¡µ
        self.notebook = ttk.Notebook(result_frame)
        self.notebook.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # æ—¥å¿—æ ‡ç­¾é¡µ
        log_frame = ttk.Frame(self.notebook)
        self.notebook.add(log_frame, text="æ“ä½œæ—¥å¿—")
        
        self.log_text = scrolledtext.ScrolledText(log_frame, height=15, width=80)
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # åˆ†æç»“æœæ ‡ç­¾é¡µ
        analysis_frame = ttk.Frame(self.notebook)
        self.notebook.add(analysis_frame, text="åˆ†æç»“æœ")
        
        self.analysis_text = scrolledtext.ScrolledText(analysis_frame, height=15, width=80)
        self.analysis_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # æ˜ å°„è¡¨æ ‡ç­¾é¡µ
        mapping_frame = ttk.Frame(self.notebook)
        self.notebook.add(mapping_frame, text="å›¾ç‰‡æ˜ å°„è¡¨")
        
        self.mapping_text = scrolledtext.ScrolledText(mapping_frame, height=15, width=80)
        self.mapping_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®æƒé‡
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(2, weight=1)
        result_frame.columnconfigure(0, weight=1)
        result_frame.rowconfigure(0, weight=1)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        analysis_frame.columnconfigure(0, weight=1)
        analysis_frame.rowconfigure(0, weight=1)
        mapping_frame.columnconfigure(0, weight=1)
        mapping_frame.rowconfigure(0, weight=1)
        
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
    
    def log(self, message):
        """æ·»åŠ æ—¥å¿—ä¿¡æ¯"""
        self.log_text.insert(tk.END, f"{message}\n")
        self.log_text.see(tk.END)
        self.root.update()
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.delete(1.0, tk.END)
    
    def select_directory(self):
        """é€‰æ‹©å·¥ä½œç›®å½•"""
        directory = filedialog.askdirectory()
        if directory:
            self.workspace_path = directory
            self.dir_var.set(directory)
            self.log(f"é€‰æ‹©å·¥ä½œç›®å½•: {directory}")
    
    def load_mapping(self):
        """åŠ è½½å›¾ç‰‡æ˜ å°„è¡¨"""
        try:
            if os.path.exists(self.mapping_file):
                with open(self.mapping_file, 'r', encoding='utf-8') as f:
                    self.image_mapping = json.load(f)
                self.update_mapping_display()
                self.log(f"åŠ è½½æ˜ å°„è¡¨: {len(self.image_mapping)} æ¡è®°å½•")
        except Exception as e:
            self.log(f"åŠ è½½æ˜ å°„è¡¨å¤±è´¥: {e}")
    
    def save_mapping(self):
        """ä¿å­˜å›¾ç‰‡æ˜ å°„è¡¨"""
        try:
            with open(self.mapping_file, 'w', encoding='utf-8') as f:
                json.dump(self.image_mapping, f, ensure_ascii=False, indent=2)
            self.update_mapping_display()
            self.log(f"ä¿å­˜æ˜ å°„è¡¨: {len(self.image_mapping)} æ¡è®°å½•")
        except Exception as e:
            self.log(f"ä¿å­˜æ˜ å°„è¡¨å¤±è´¥: {e}")
    
    def update_mapping_display(self):
        """æ›´æ–°æ˜ å°„è¡¨æ˜¾ç¤º"""
        self.mapping_text.delete(1.0, tk.END)
        if self.image_mapping:
            for local_path, remote_url in self.image_mapping.items():
                self.mapping_text.insert(tk.END, f"æœ¬åœ°: {local_path}\n")
                self.mapping_text.insert(tk.END, f"è¿œç¨‹: {remote_url}\n")
                self.mapping_text.insert(tk.END, "-" * 80 + "\n")    

    def scan_files(self):
        """æ‰«æåˆ†æMDæ–‡ä»¶å’Œå›¾ç‰‡"""
        if not self.workspace_path:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆé€‰æ‹©å·¥ä½œç›®å½•")
            return
        
        def scan_thread():
            try:
                self.log("å¼€å§‹æ‰«ææ–‡ä»¶...")
                
                # æ‰«æMDæ–‡ä»¶
                self.md_files = []
                self.image_files = []
                self.image_references = {}
                self.invalid_images = {}
                self.referenced_local_images = []
                self.remote_images = []
                
                for root, dirs, files in os.walk(self.workspace_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # æ ‡å‡†åŒ–è·¯å¾„æ ¼å¼å¹¶è§„èŒƒåŒ–åˆ†éš”ç¬¦
                        file_path = self.normalize_path(os.path.normpath(file_path))
                        if file.lower().endswith('.md'):
                            self.md_files.append(file_path)
                        elif any(file.lower().endswith(ext) for ext in self.image_extensions):
                            self.image_files.append(file_path)
                
                self.log(f"æ‰¾åˆ° {len(self.md_files)} ä¸ªMDæ–‡ä»¶")
                self.log(f"æ‰¾åˆ° {len(self.image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
                
                # æ˜¾ç¤ºå›¾ç‰‡æ–‡ä»¶çš„ä¸€äº›ç¤ºä¾‹è·¯å¾„
                if self.image_files:
                    self.log("æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ç¤ºä¾‹:")
                    for i, img in enumerate(self.image_files[:3]):
                        rel_path = self.safe_relpath(img, self.workspace_path)
                        self.log(f"  {i+1}. {rel_path}")
                    if len(self.image_files) > 3:
                        self.log(f"  ... è¿˜æœ‰ {len(self.image_files) - 3} ä¸ªæ–‡ä»¶")
                
                # åˆ†æå›¾ç‰‡å¼•ç”¨
                referenced_images = set()
                
                for md_file in self.md_files:
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # æŸ¥æ‰¾å›¾ç‰‡å¼•ç”¨ ![](path) å’Œ <img src="path">
                        img_patterns = [
                            r'!\[.*?\]\((.*?)\)',  # ![alt](path)
                            r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>',  # <img src="path">
                        ]
                        
                        file_images = []
                        file_invalid = []
                        
                        for pattern in img_patterns:
                            matches = re.findall(pattern, content, re.IGNORECASE)
                            for match in matches:
                                img_path = match.strip()
                                if img_path:
                                    # å¤„ç†ç›¸å¯¹è·¯å¾„
                                    if not (img_path.startswith('http') or img_path.startswith('https')):
                                        # ç›¸å¯¹äºMDæ–‡ä»¶çš„è·¯å¾„
                                        abs_img_path = os.path.join(os.path.dirname(md_file), img_path)
                                        abs_img_path = self.normalize_path(os.path.normpath(abs_img_path))
                                        
                                        if os.path.exists(abs_img_path):
                                            file_images.append(abs_img_path)
                                            referenced_images.add(abs_img_path)
                                        else:
                                            file_invalid.append(img_path)
                                    else:
                                        # è¿œç¨‹å›¾ç‰‡
                                        file_images.append(img_path)
                        
                        if file_images:
                            self.image_references[md_file] = file_images
                        if file_invalid:
                            self.invalid_images[md_file] = file_invalid
                    
                    except Exception as e:
                        self.log(f"åˆ†ææ–‡ä»¶ {md_file} æ—¶å‡ºé”™: {e}")
                
                # æ‰¾å‡ºæœªè¢«å¼•ç”¨çš„å›¾ç‰‡
                # æ ‡å‡†åŒ–referenced_imagesä¸­çš„è·¯å¾„
                referenced_images_normalized = {os.path.normpath(path) for path in referenced_images}
                
                self.unused_images = []
                for img_file in self.image_files:
                    # æ ‡å‡†åŒ–å½“å‰å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                    img_file_normalized = os.path.normpath(img_file)
                    if img_file_normalized not in referenced_images_normalized:
                        self.unused_images.append(img_file)
                
                # ç»Ÿè®¡è¢«å¼•ç”¨çš„å›¾ç‰‡
                self.referenced_local_images = list(referenced_images)
                
                # ç®€åŒ–çš„ç»Ÿè®¡éªŒè¯
                actual_unused = len(self.image_files) - len(referenced_images)
                if abs(len(self.unused_images) - actual_unused) > 10:  # å…è®¸å°å·®å¼‚
                    self.log(f"âš ï¸ æ³¨æ„ï¼šç»Ÿè®¡å¯èƒ½æœ‰å°å·®å¼‚ï¼Œè¿™é€šå¸¸æ˜¯ç”±äºé‡å¤å¼•ç”¨é€ æˆçš„")
                
                # ç»Ÿè®¡è¿œç¨‹å›¾ç‰‡
                self.remote_images = []
                for images in self.image_references.values():
                    for img in images:
                        if img.startswith('http') and img not in self.remote_images:
                            self.remote_images.append(img)
                
                self.log("æ‰«æå®Œæˆ!")
                self.display_analysis_results()
                
            except Exception as e:
                self.log(f"æ‰«æå¤±è´¥: {e}")
        
        threading.Thread(target=scan_thread, daemon=True).start()
    
    def display_analysis_results(self):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        self.analysis_text.delete(1.0, tk.END)
        
        # æ˜¾ç¤ºMDæ–‡ä»¶åŠå…¶å¼•ç”¨çš„å›¾ç‰‡
        self.analysis_text.insert(tk.END, "=== MDæ–‡ä»¶å›¾ç‰‡å¼•ç”¨åˆ†æ ===\n\n")
        for md_file, images in self.image_references.items():
            rel_md = self.safe_relpath(md_file, self.workspace_path)
            self.analysis_text.insert(tk.END, f"ğŸ“„ {rel_md}\n")
            for img in images:
                if img.startswith('http'):
                    self.analysis_text.insert(tk.END, f"  ğŸŒ {img}\n")
                else:
                    rel_img = self.safe_relpath(img, self.workspace_path)
                    self.analysis_text.insert(tk.END, f"  ğŸ–¼ï¸  {rel_img}\n")
            self.analysis_text.insert(tk.END, "\n")
        
        # æ˜¾ç¤ºæ— æ•ˆå›¾ç‰‡
        if self.invalid_images:
            self.analysis_text.insert(tk.END, "=== æ— æ•ˆå›¾ç‰‡å¼•ç”¨ ===\n\n")
            for md_file, invalid_imgs in self.invalid_images.items():
                rel_md = self.safe_relpath(md_file, self.workspace_path)
                self.analysis_text.insert(tk.END, f"ğŸ“„ {rel_md}\n")
                for img in invalid_imgs:
                    self.analysis_text.insert(tk.END, f"  âŒ {img}\n")
                self.analysis_text.insert(tk.END, "\n")
        
        # æ˜¾ç¤ºæœªè¢«å¼•ç”¨çš„å›¾ç‰‡
        if self.unused_images:
            self.analysis_text.insert(tk.END, "=== æœªè¢«å¼•ç”¨çš„å›¾ç‰‡ ===\n\n")
            for img in self.unused_images:
                rel_img = self.safe_relpath(img, self.workspace_path)
                self.analysis_text.insert(tk.END, f"ğŸ—‘ï¸  {rel_img}\n")
        
        # ç»Ÿè®¡ä¿¡æ¯
        # ä½¿ç”¨referenced_local_imagesçš„å®é™…å¤§å°ï¼Œå› ä¸ºè·¯å¾„åŒ¹é…å¯èƒ½æœ‰é—®é¢˜
        referenced_local_count = len(getattr(self, 'referenced_local_images', []))
        unused_count = len(self.image_files) - referenced_local_count if referenced_local_count > 0 else len(self.unused_images)
        
        self.analysis_text.insert(tk.END, f"\n=== ç»Ÿè®¡ä¿¡æ¯ ===\n")
        self.analysis_text.insert(tk.END, f"MDæ–‡ä»¶æ€»æ•°: {len(self.md_files)}\n")
        self.analysis_text.insert(tk.END, f"æœ¬åœ°å›¾ç‰‡æ–‡ä»¶æ€»æ•°: {len(self.image_files)}\n")
        self.analysis_text.insert(tk.END, f"è¢«å¼•ç”¨çš„æœ¬åœ°å›¾ç‰‡æ•°: {referenced_local_count}\n")
        self.analysis_text.insert(tk.END, f"è¢«å¼•ç”¨çš„è¿œç¨‹å›¾ç‰‡æ•°: {len(getattr(self, 'remote_images', []))}\n")
        self.analysis_text.insert(tk.END, f"æœªè¢«å¼•ç”¨çš„æœ¬åœ°å›¾ç‰‡æ•°: {unused_count}\n")
        self.analysis_text.insert(tk.END, f"æ— æ•ˆå¼•ç”¨æ•°: {sum(len(imgs) for imgs in self.invalid_images.values())}\n")
        self.analysis_text.insert(tk.END, f"å›¾ç‰‡æ˜ å°„è®°å½•æ•°: {len(self.image_mapping)}\n")
    
    def upload_images(self):
        """ä¸Šä¼ å›¾ç‰‡åˆ°å›¾åºŠï¼ˆé€šè¿‡PicListï¼‰"""
        if not self.image_references:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆæ‰«æåˆ†ææ–‡ä»¶")
            return
        
        # é€‰æ‹©è¦å¤„ç†çš„MDæ–‡ä»¶
        md_files = list(self.image_references.keys())
        if not md_files:
            messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰æ‰¾åˆ°åŒ…å«å›¾ç‰‡çš„MDæ–‡ä»¶")
            return
        
        # åˆ›å»ºé€‰æ‹©å¯¹è¯æ¡†
        selection_window = tk.Toplevel(self.root)
        selection_window.title("é€‰æ‹©MDæ–‡ä»¶")
        selection_window.geometry("600x400")
        
        ttk.Label(selection_window, text="é€‰æ‹©è¦ä¸Šä¼ å›¾ç‰‡çš„MDæ–‡ä»¶:").pack(pady=10)
        
        # æ–‡ä»¶åˆ—è¡¨
        listbox_frame = ttk.Frame(selection_window)
        listbox_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        scrollbar = ttk.Scrollbar(listbox_frame)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        listbox = tk.Listbox(listbox_frame, yscrollcommand=scrollbar.set, selectmode=tk.MULTIPLE)
        listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.config(command=listbox.yview)
        
        for md_file in md_files:
            rel_path = self.safe_relpath(md_file, self.workspace_path)
            listbox.insert(tk.END, rel_path)
        
        def upload_selected():
            selected_indices = listbox.curselection()
            if not selected_indices:
                messagebox.showwarning("è­¦å‘Š", "è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªMDæ–‡ä»¶")
                return
            
            selected_files = [md_files[i] for i in selected_indices]
            selection_window.destroy()
            self.perform_upload(selected_files)
        
        button_frame = ttk.Frame(selection_window)
        button_frame.pack(pady=10)
        
        ttk.Button(button_frame, text="ä¸Šä¼ ", command=upload_selected).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="å–æ¶ˆ", command=selection_window.destroy).pack(side=tk.LEFT, padx=5)
    
    def perform_upload(self, md_files):
        """æ‰§è¡Œå›¾ç‰‡ä¸Šä¼ """
        def upload_thread():
            try:
                self.log("å¼€å§‹ä¸Šä¼ å›¾ç‰‡åˆ°å›¾åºŠ...")
                
                for md_file in md_files:
                    rel_md = self.safe_relpath(md_file, self.workspace_path)
                    self.log(f"å¤„ç†æ–‡ä»¶: {rel_md}")
                    
                    images = self.image_references.get(md_file, [])
                    local_images = [img for img in images if not img.startswith('http')]
                    
                    for img_path in local_images:
                        if img_path in self.image_mapping:
                            self.log(f"  è·³è¿‡å·²ä¸Šä¼ : {os.path.basename(img_path)}")
                            continue
                        
                        try:
                            # ä½¿ç”¨PicListä¸Šä¼ å›¾ç‰‡
                            remote_url = self.upload_to_piclist(img_path)
                            if remote_url:
                                self.image_mapping[img_path] = remote_url
                                self.log(f"  âœ… ä¸Šä¼ æˆåŠŸ: {os.path.basename(img_path)} -> {remote_url}")
                            else:
                                self.log(f"  âŒ ä¸Šä¼ å¤±è´¥: {os.path.basename(img_path)}")
                        
                        except Exception as e:
                            self.log(f"  âŒ ä¸Šä¼ å‡ºé”™: {os.path.basename(img_path)} - {e}")
                
                self.save_mapping()
                self.log("å›¾ç‰‡ä¸Šä¼ å®Œæˆ!")
                
            except Exception as e:
                self.log(f"ä¸Šä¼ å¤±è´¥: {e}")
        
        threading.Thread(target=upload_thread, daemon=True).start()
    
    def upload_to_piclist(self, image_path):
        """é€šè¿‡PicListä¸Šä¼ å›¾ç‰‡"""
        try:
            # å°è¯•è°ƒç”¨PicListå‘½ä»¤è¡Œæ¥å£
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„PicListå®‰è£…æƒ…å†µè°ƒæ•´å‘½ä»¤
            cmd = ['piclist', 'upload', image_path]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                # ä»è¾“å‡ºä¸­æå–URLï¼ˆéœ€è¦æ ¹æ®PicListçš„å®é™…è¾“å‡ºæ ¼å¼è°ƒæ•´ï¼‰
                output = result.stdout.strip()
                # å‡è®¾PicListè¿”å›çš„æ˜¯URL
                if output.startswith('http'):
                    return output
            
            # å¦‚æœPicListä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹ŸURLï¼ˆç”¨äºæµ‹è¯•ï¼‰
            filename = os.path.basename(image_path)
            return f"https://example.com/images/{filename}"
            
        except subprocess.TimeoutExpired:
            self.log(f"ä¸Šä¼ è¶…æ—¶: {image_path}")
            return None
        except FileNotFoundError:
            self.log("PicListæœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…PicList")
            # è¿”å›æ¨¡æ‹ŸURLç”¨äºæµ‹è¯•
            filename = os.path.basename(image_path)
            return f"https://example.com/images/{filename}"
        except Exception as e:
            self.log(f"PicListä¸Šä¼ å‡ºé”™: {e}")
            return None   
 
    def replace_to_remote(self):
        """æ›¿æ¢å›¾ç‰‡é“¾æ¥ä¸ºè¿œç¨‹URL"""
        if not self.image_mapping:
            messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ˜ å°„è®°å½•")
            return
        
        def replace_thread():
            try:
                self.log("å¼€å§‹æ›¿æ¢ä¸ºè¿œç¨‹é“¾æ¥...")
                
                for md_file in self.md_files:
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        original_content = content
                        replaced_count = 0
                        
                        # æ›¿æ¢å›¾ç‰‡é“¾æ¥
                        for local_path, remote_url in self.image_mapping.items():
                            # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¤„ç†è·¨é©±åŠ¨å™¨æƒ…å†µ
                            rel_path = self.safe_relpath(local_path, os.path.dirname(md_file))
                            local_path_normalized = self.normalize_path(local_path)
                            
                            # æ›¿æ¢å„ç§å¯èƒ½çš„è·¯å¾„æ ¼å¼
                            patterns = [
                                f'!\\[([^\\]]*)\\]\\({re.escape(rel_path)}\\)',
                                f'!\\[([^\\]]*)\\]\\({re.escape(local_path_normalized)}\\)',
                                f'!\\[([^\\]]*)\\]\\({re.escape(local_path)}\\)',
                                f'<img([^>]+)src=["\']{re.escape(rel_path)}["\'](.*?)>',
                                f'<img([^>]+)src=["\']{re.escape(local_path_normalized)}["\'](.*?)>',
                                f'<img([^>]+)src=["\']{re.escape(local_path)}["\'](.*?)>',
                            ]
                            
                            for pattern in patterns:
                                if '!\\[' in pattern:
                                    # Markdownæ ¼å¼
                                    new_content = re.sub(pattern, f'![\\1]({remote_url})', content)
                                else:
                                    # HTMLæ ¼å¼
                                    new_content = re.sub(pattern, f'<img\\1src="{remote_url}"\\2>', content)
                                
                                if new_content != content:
                                    content = new_content
                                    replaced_count += 1
                                    break
                        
                        # å¦‚æœæœ‰æ›¿æ¢ï¼Œä¿å­˜æ–‡ä»¶
                        if content != original_content:
                            with open(md_file, 'w', encoding='utf-8') as f:
                                f.write(content)
                            
                            rel_md = self.safe_relpath(md_file, self.workspace_path)
                            self.log(f"âœ… {rel_md}: æ›¿æ¢äº† {replaced_count} ä¸ªå›¾ç‰‡é“¾æ¥")
                    
                    except Exception as e:
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        self.log(f"âŒ å¤„ç† {rel_md} æ—¶å‡ºé”™: {e}")
                
                self.log("æ›¿æ¢ä¸ºè¿œç¨‹é“¾æ¥å®Œæˆ!")
                
            except Exception as e:
                self.log(f"æ›¿æ¢å¤±è´¥: {e}")
        
        threading.Thread(target=replace_thread, daemon=True).start()
    
    def replace_to_local(self):
        """æ›¿æ¢å›¾ç‰‡é“¾æ¥ä¸ºæœ¬åœ°è·¯å¾„"""
        if not self.image_mapping:
            messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ˜ å°„è®°å½•")
            return
        
        def replace_thread():
            try:
                self.log("å¼€å§‹æ›¿æ¢ä¸ºæœ¬åœ°é“¾æ¥...")
                
                # åˆ›å»ºåå‘æ˜ å°„
                reverse_mapping = {remote_url: local_path for local_path, remote_url in self.image_mapping.items()}
                
                for md_file in self.md_files:
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        original_content = content
                        replaced_count = 0
                        
                        # æ›¿æ¢è¿œç¨‹é“¾æ¥ä¸ºæœ¬åœ°è·¯å¾„
                        for remote_url, local_path in reverse_mapping.items():
                            if remote_url in content:
                                # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¤„ç†è·¨é©±åŠ¨å™¨æƒ…å†µ
                                rel_path = self.safe_relpath(local_path, os.path.dirname(md_file))
                                
                                # æ›¿æ¢å„ç§æ ¼å¼
                                patterns = [
                                    (f'!\\[([^\\]]*)\\]\\({re.escape(remote_url)}\\)', f'![\\1]({rel_path})'),
                                    (f'<img([^>]+)src=["\']{re.escape(remote_url)}["\'](.*?)>', f'<img\\1src="{rel_path}"\\2>'),
                                ]
                                
                                for pattern, replacement in patterns:
                                    new_content = re.sub(pattern, replacement, content)
                                    if new_content != content:
                                        content = new_content
                                        replaced_count += 1
                                        break
                        
                        # å¦‚æœæœ‰æ›¿æ¢ï¼Œä¿å­˜æ–‡ä»¶
                        if content != original_content:
                            with open(md_file, 'w', encoding='utf-8') as f:
                                f.write(content)
                            
                            rel_md = self.safe_relpath(md_file, self.workspace_path)
                            self.log(f"âœ… {rel_md}: æ›¿æ¢äº† {replaced_count} ä¸ªå›¾ç‰‡é“¾æ¥")
                    
                    except Exception as e:
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        self.log(f"âŒ å¤„ç† {rel_md} æ—¶å‡ºé”™: {e}")
                
                self.log("æ›¿æ¢ä¸ºæœ¬åœ°é“¾æ¥å®Œæˆ!")
                
            except Exception as e:
                self.log(f"æ›¿æ¢å¤±è´¥: {e}")
        
        threading.Thread(target=replace_thread, daemon=True).start()
    
    def download_images(self):
        """ä¸‹è½½è¿œç¨‹å›¾ç‰‡åˆ°æœ¬åœ°"""
        def download_thread():
            try:
                self.log("å¼€å§‹ä¸‹è½½è¿œç¨‹å›¾ç‰‡...")
                
                for md_file in self.md_files:
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # æŸ¥æ‰¾è¿œç¨‹å›¾ç‰‡é“¾æ¥
                        img_patterns = [
                            r'!\[.*?\]\((https?://[^)]+)\)',
                            r'<img[^>]+src=["\'](https?://[^"\']+)["\'][^>]*>',
                        ]
                        
                        remote_urls = set()
                        for pattern in img_patterns:
                            matches = re.findall(pattern, content, re.IGNORECASE)
                            remote_urls.update(matches)
                        
                        if not remote_urls:
                            continue
                        
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        self.log(f"å¤„ç†æ–‡ä»¶: {rel_md}")
                        
                        # åˆ›å»ºå›¾ç‰‡ç›®å½•
                        md_dir = os.path.dirname(md_file)
                        img_dir = os.path.join(md_dir, 'images')
                        os.makedirs(img_dir, exist_ok=True)
                        
                        updated_content = content
                        
                        for remote_url in remote_urls:
                            try:
                                # è·å–æ–‡ä»¶å
                                parsed_url = urlparse(remote_url)
                                filename = os.path.basename(parsed_url.path)
                                if not filename or '.' not in filename:
                                    filename = f"image_{hash(remote_url) % 10000}.jpg"
                                
                                local_path = self.normalize_path(os.path.join(img_dir, filename))
                                
                                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡
                                if os.path.exists(local_path):
                                    self.log(f"  è·³è¿‡å·²å­˜åœ¨: {filename}")
                                    continue
                                
                                # ä¸‹è½½å›¾ç‰‡ï¼ˆå¸¦é‡è¯•å’Œç‰¹æ®Šå¤„ç†ï¼‰
                                success = self.download_image_with_retry(remote_url, local_path)
                                
                                if success:
                                    # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¤„ç†è·¨é©±åŠ¨å™¨æƒ…å†µ
                                    rel_img_path = self.safe_relpath(local_path, md_dir)
                                    
                                    # æ›´æ–°æ˜ å°„è¡¨
                                    self.image_mapping[local_path] = remote_url
                                    
                                    # æ›¿æ¢å†…å®¹ä¸­çš„é“¾æ¥
                                    updated_content = updated_content.replace(remote_url, rel_img_path)
                                    
                                    self.log(f"  âœ… ä¸‹è½½æˆåŠŸ: {filename}")
                                else:
                                    self.log(f"  âŒ ä¸‹è½½å¤±è´¥: {filename} - æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
                            
                            except Exception as e:
                                self.log(f"  âŒ ä¸‹è½½å¤±è´¥ {remote_url}: {e}")
                        
                        # ä¿å­˜æ›´æ–°åçš„MDæ–‡ä»¶
                        if updated_content != content:
                            with open(md_file, 'w', encoding='utf-8') as f:
                                f.write(updated_content)
                    
                    except Exception as e:
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        self.log(f"âŒ å¤„ç† {rel_md} æ—¶å‡ºé”™: {e}")
                
                self.save_mapping()
                self.log("ä¸‹è½½è¿œç¨‹å›¾ç‰‡å®Œæˆ!")
                
            except Exception as e:
                self.log(f"ä¸‹è½½å¤±è´¥: {e}")
        
        threading.Thread(target=download_thread, daemon=True).start()
    
    def delete_local_images(self):
        """åˆ é™¤æœ¬åœ°å›¾ç‰‡æ–‡ä»¶"""
        if not self.unused_images and not self.image_mapping:
            messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰æ‰¾åˆ°å¯åˆ é™¤çš„å›¾ç‰‡")
            return
        
        # ç¡®è®¤å¯¹è¯æ¡†
        result = messagebox.askyesno(
            "ç¡®è®¤åˆ é™¤", 
            f"å°†åˆ é™¤ä»¥ä¸‹å†…å®¹ï¼š\n"
            f"- {len(self.unused_images)} ä¸ªæœªè¢«å¼•ç”¨çš„å›¾ç‰‡\n"
            f"- {len(self.image_mapping)} ä¸ªå·²ä¸Šä¼ çš„æœ¬åœ°å›¾ç‰‡\n"
            f"- æ¸…ç©ºå›¾ç‰‡æ˜ å°„è®°å½•\n\n"
            f"æ­¤æ“ä½œä¸å¯æ¢å¤ï¼Œç¡®å®šç»§ç»­å—ï¼Ÿ"
        )
        
        if not result:
            return
        
        def delete_thread():
            try:
                self.log("å¼€å§‹åˆ é™¤æœ¬åœ°å›¾ç‰‡...")
                
                deleted_count = 0
                
                # åˆ é™¤æœªè¢«å¼•ç”¨çš„å›¾ç‰‡
                for img_path in self.unused_images:
                    try:
                        if os.path.exists(img_path):
                            os.remove(img_path)
                            deleted_count += 1
                            rel_path = self.safe_relpath(img_path, self.workspace_path)
                            self.log(f"âœ… åˆ é™¤æœªå¼•ç”¨å›¾ç‰‡: {rel_path}")
                    except Exception as e:
                        rel_path = self.safe_relpath(img_path, self.workspace_path)
                        self.log(f"âŒ åˆ é™¤å¤±è´¥ {rel_path}: {e}")
                
                # åˆ é™¤å·²ä¸Šä¼ çš„æœ¬åœ°å›¾ç‰‡
                for local_path in list(self.image_mapping.keys()):
                    try:
                        if os.path.exists(local_path):
                            os.remove(local_path)
                            deleted_count += 1
                            rel_path = self.safe_relpath(local_path, self.workspace_path)
                            self.log(f"âœ… åˆ é™¤å·²ä¸Šä¼ å›¾ç‰‡: {rel_path}")
                    except Exception as e:
                        rel_path = self.safe_relpath(local_path, self.workspace_path)
                        self.log(f"âŒ åˆ é™¤å¤±è´¥ {rel_path}: {e}")
                
                # æ¸…ç©ºæ˜ å°„è®°å½•
                self.image_mapping.clear()
                self.save_mapping()
                
                # æ¸…ç©ºåˆ†æç»“æœ
                self.unused_images.clear()
                
                self.log(f"åˆ é™¤å®Œæˆ! å…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶")
                
            except Exception as e:
                self.log(f"åˆ é™¤å¤±è´¥: {e}")
        
        threading.Thread(target=delete_thread, daemon=True).start()
    
    def fix_broken_links(self):
        """ä¿®å¤å¤±æ•ˆçš„å›¾ç‰‡é“¾æ¥"""
        def fix_thread():
            try:
                self.log("å¼€å§‹ä¿®å¤å¤±æ•ˆé“¾æ¥...")
                
                broken_links = []
                
                # æ£€æŸ¥æ‰€æœ‰MDæ–‡ä»¶ä¸­çš„è¿œç¨‹é“¾æ¥
                for md_file in self.md_files:
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # æŸ¥æ‰¾è¿œç¨‹å›¾ç‰‡é“¾æ¥
                        img_patterns = [
                            r'!\[.*?\]\((https?://[^)]+)\)',
                            r'<img[^>]+src=["\'](https?://[^"\']+)["\'][^>]*>',
                        ]
                        
                        remote_urls = set()
                        for pattern in img_patterns:
                            matches = re.findall(pattern, content, re.IGNORECASE)
                            remote_urls.update(matches)
                        
                        # æ£€æŸ¥æ¯ä¸ªé“¾æ¥çš„å¯è®¿é—®æ€§
                        for url in remote_urls:
                            try:
                                response = requests.head(url, timeout=10, allow_redirects=True)
                                if response.status_code not in [200, 301, 302]:
                                    broken_links.append((md_file, url, response.status_code))
                                    self.log(f"  âŒ å¤±æ•ˆé“¾æ¥: {url} (çŠ¶æ€ç : {response.status_code})")
                            except Exception as e:
                                broken_links.append((md_file, url, str(e)))
                                self.log(f"  âŒ æ— æ³•è®¿é—®: {url} ({str(e)})")
                    
                    except Exception as e:
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        self.log(f"âŒ æ£€æŸ¥æ–‡ä»¶ {rel_md} æ—¶å‡ºé”™: {e}")
                
                if broken_links:
                    self.log(f"\nå‘ç° {len(broken_links)} ä¸ªå¤±æ•ˆé“¾æ¥")
                    
                    # æä¾›ä¿®å¤å»ºè®®
                    gitee_links = [link for link in broken_links if 'gitee.com' in link[1]]
                    if gitee_links:
                        self.log("\n=== Giteeé“¾æ¥ä¿®å¤å»ºè®® ===")
                        self.log("Giteeå›¾åºŠç»å¸¸å‡ºç°403é”™è¯¯ï¼Œå»ºè®®:")
                        self.log("1. å°†å›¾ç‰‡é‡æ–°ä¸Šä¼ åˆ°å…¶ä»–å›¾åºŠï¼ˆå¦‚GitHubã€ä¸ƒç‰›äº‘ç­‰ï¼‰")
                        self.log("2. ä½¿ç”¨æœ¬åœ°å›¾ç‰‡å­˜å‚¨")
                        self.log("3. æ£€æŸ¥Giteeä»“åº“çš„è®¿é—®æƒé™è®¾ç½®")
                        
                        for md_file, url, error in gitee_links:
                            rel_md = self.safe_relpath(md_file, self.workspace_path)
                            self.log(f"  ğŸ“„ {rel_md}")
                            self.log(f"     ğŸ”— {url}")
                else:
                    self.log("âœ… æ‰€æœ‰è¿œç¨‹é“¾æ¥éƒ½å¯ä»¥æ­£å¸¸è®¿é—®")
                
                self.log("å¤±æ•ˆé“¾æ¥æ£€æŸ¥å®Œæˆ!")
                
            except Exception as e:
                self.log(f"ä¿®å¤å¤±æ•ˆé“¾æ¥å¤±è´¥: {e}")
        
        threading.Thread(target=fix_thread, daemon=True).start()
    
    def smart_fix_paths(self):
        """æ™ºèƒ½ä¿®å¤è·¯å¾„é—®é¢˜ - å¤„ç†æ–‡ä»¶å¤¹ç§»åŠ¨ç­‰æƒ…å†µ"""
        if not self.invalid_images:
            messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰å‘ç°æ— æ•ˆå¼•ç”¨éœ€è¦ä¿®å¤")
            return
        
        # å®‰å…¨ç¡®è®¤å¯¹è¯æ¡†
        total_invalid = sum(len(imgs) for imgs in self.invalid_images.values())
        result = messagebox.askyesno(
            "æ™ºèƒ½ä¿®å¤ç¡®è®¤", 
            f"å°†è¦æ™ºèƒ½ä¿®å¤ {total_invalid} ä¸ªæ— æ•ˆå¼•ç”¨\n\n"
            f"å®‰å…¨æªæ–½ï¼š\n"
            f"âœ… è‡ªåŠ¨å¤‡ä»½åŸå§‹æ–‡ä»¶\n"
            f"âœ… è®°å½•æ‰€æœ‰ä¿®æ”¹æ“ä½œ\n"
            f"âœ… ç”Ÿæˆä¿®å¤æŠ¥å‘Š\n"
            f"âœ… å¯ä»¥æ’¤é”€ä¿®æ”¹\n\n"
            f"ç¡®å®šç»§ç»­å—ï¼Ÿ"
        )
        
        if not result:
            return
        
        def fix_thread():
            try:
                import datetime
                import shutil
                
                self.log("å¼€å§‹æ™ºèƒ½ä¿®å¤è·¯å¾„...")
                self.log(f"å‘ç° {sum(len(imgs) for imgs in self.invalid_images.values())} ä¸ªæ— æ•ˆå¼•ç”¨")
                
                # åˆ›å»ºå¤‡ä»½å’Œæ—¥å¿—ç›®å½•
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_base = os.path.join(self.workspace_path, ".backup")
                backup_dir = os.path.join(backup_base, f"smart_fix_{timestamp}")
                os.makedirs(backup_dir, exist_ok=True)
                
                # åˆ›å»ºä¿®å¤è®°å½•æ–‡ä»¶
                fix_log_file = os.path.join(backup_dir, "fix_log.json")
                fix_records = {
                    "timestamp": timestamp,
                    "total_files_processed": 0,
                    "total_fixes": 0,
                    "modifications": []
                }
                
                self.log(f"åˆ›å»ºå¤‡ä»½ç›®å½•: {backup_dir}")
                
                # åˆ›å»ºæ–‡ä»¶ååˆ°è·¯å¾„çš„æ˜ å°„
                filename_to_paths = {}
                for img_path in self.image_files:
                    filename = os.path.basename(img_path).lower()
                    if filename not in filename_to_paths:
                        filename_to_paths[filename] = []
                    filename_to_paths[filename].append(img_path)
                
                self.log(f"å»ºç«‹äº† {len(filename_to_paths)} ä¸ªæ–‡ä»¶åæ˜ å°„")
                
                total_fixed = 0
                total_invalid = 0
                
                for md_file, invalid_imgs in self.invalid_images.items():
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        original_content = content
                        fixed_count = 0
                        
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        self.log(f"\nå¤„ç†æ–‡ä»¶: {rel_md}")
                        
                        # å¤‡ä»½åŸå§‹æ–‡ä»¶
                        backup_file = os.path.join(backup_dir, f"{os.path.basename(md_file)}.backup")
                        shutil.copy2(md_file, backup_file)
                        
                        # è®°å½•æ–‡ä»¶å¤„ç†
                        file_record = {
                            "file": rel_md,
                            "backup_file": backup_file,
                            "original_invalid_count": len(invalid_imgs),
                            "fixes": []
                        }
                        
                        for invalid_path in invalid_imgs:
                            total_invalid += 1
                            self.log(f"  ğŸ” æ£€æŸ¥è·¯å¾„: {invalid_path}")
                            
                            # é¦–å…ˆç”¨åŸå§‹è·¯å¾„çš„æ–‡ä»¶åæŸ¥æ‰¾
                            original_filename = os.path.basename(invalid_path).lower()
                            
                            # æŸ¥æ‰¾åŒåæ–‡ä»¶
                            if original_filename in filename_to_paths:
                                candidates = filename_to_paths[original_filename]
                                
                                if len(candidates) == 1:
                                    # åªæœ‰ä¸€ä¸ªå€™é€‰ï¼Œç›´æ¥æ›¿æ¢
                                    correct_path = candidates[0]
                                    rel_correct_path = self.safe_relpath(correct_path, os.path.dirname(md_file))
                                    
                                    # æ›¿æ¢å†…å®¹ä¸­çš„è·¯å¾„
                                    old_patterns = [
                                        f'!\\[([^\\]]*)\\]\\({re.escape(invalid_path)}\\)',
                                        f'<img([^>]+)src=["\']{re.escape(invalid_path)}["\'](.*?)>',
                                    ]
                                    
                                    for pattern in old_patterns:
                                        if '!\\[' in pattern:
                                            new_content = re.sub(pattern, f'![\\1]({rel_correct_path})', content)
                                        else:
                                            new_content = re.sub(pattern, f'<img\\1src="{rel_correct_path}"\\2>', content)
                                        
                                        if new_content != content:
                                            content = new_content
                                            fixed_count += 1
                                            total_fixed += 1
                                            
                                            # è®°å½•ä¿®å¤æ“ä½œ
                                            fix_detail = {
                                                "type": "exact_match",
                                                "original_path": invalid_path,
                                                "new_path": rel_correct_path,
                                                "absolute_path": correct_path,
                                                "confidence": "high"
                                            }
                                            file_record["fixes"].append(fix_detail)
                                            
                                            self.log(f"  âœ… ä¿®å¤: {invalid_path} -> {rel_correct_path}")
                                            break
                                
                                elif len(candidates) > 1:
                                    # å¤šä¸ªå€™é€‰ï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„è·¯å¾„
                                    best_match = self.find_best_path_match(invalid_path, candidates)
                                    if best_match:
                                        rel_best_path = self.safe_relpath(best_match, os.path.dirname(md_file))
                                        
                                        # æ›¿æ¢å†…å®¹ä¸­çš„è·¯å¾„
                                        old_patterns = [
                                            f'!\\[([^\\]]*)\\]\\({re.escape(invalid_path)}\\)',
                                            f'<img([^>]+)src=["\']{re.escape(invalid_path)}["\'](.*?)>',
                                        ]
                                        
                                        for pattern in old_patterns:
                                            if '!\\[' in pattern:
                                                new_content = re.sub(pattern, f'![\\1]({rel_best_path})', content)
                                            else:
                                                new_content = re.sub(pattern, f'<img\\1src="{rel_best_path}"\\2>', content)
                                            
                                            if new_content != content:
                                                content = new_content
                                                fixed_count += 1
                                                total_fixed += 1
                                                
                                                # è®°å½•æ™ºèƒ½åŒ¹é…æ“ä½œ
                                                similarity_score = self.calculate_similarity(invalid_path, best_match)
                                                fix_detail = {
                                                    "type": "smart_match",
                                                    "original_path": invalid_path,
                                                    "new_path": rel_best_path,
                                                    "absolute_path": best_match,
                                                    "confidence": "medium" if similarity_score > 0.7 else "low",
                                                    "similarity_score": similarity_score,
                                                    "candidates_count": len(candidates)
                                                }
                                                file_record["fixes"].append(fix_detail)
                                                
                                                self.log(f"  âœ… æ™ºèƒ½åŒ¹é…: {invalid_path} -> {rel_best_path} (ç›¸ä¼¼åº¦: {similarity_score:.2f})")
                                                break
                            else:
                                # åŸå§‹æ–‡ä»¶åæ‰¾ä¸åˆ°ï¼Œå°è¯•URLè§£ç 
                                decoded_path = unquote(invalid_path)
                                if decoded_path != invalid_path:
                                    self.log(f"  ğŸ”“ å°è¯•URLè§£ç : {decoded_path}")
                                    
                                    # ç”¨è§£ç åçš„æ–‡ä»¶åå†æ¬¡æŸ¥æ‰¾
                                    decoded_filename = os.path.basename(decoded_path).lower()
                                    if decoded_filename in filename_to_paths:
                                        candidates = filename_to_paths[decoded_filename]
                                        
                                        if len(candidates) == 1:
                                            # åªæœ‰ä¸€ä¸ªå€™é€‰ï¼Œç›´æ¥æ›¿æ¢
                                            correct_path = candidates[0]
                                            rel_correct_path = self.safe_relpath(correct_path, os.path.dirname(md_file))
                                            
                                            # æ›¿æ¢å†…å®¹ä¸­çš„è·¯å¾„
                                            old_patterns = [
                                                f'!\\[([^\\]]*)\\]\\({re.escape(invalid_path)}\\)',
                                                f'<img([^>]+)src=["\']{re.escape(invalid_path)}["\'](.*?)>',
                                            ]
                                            
                                            for pattern in old_patterns:
                                                if '!\\[' in pattern:
                                                    new_content = re.sub(pattern, f'![\\1]({rel_correct_path})', content)
                                                else:
                                                    new_content = re.sub(pattern, f'<img\\1src="{rel_correct_path}"\\2>', content)
                                                
                                                if new_content != content:
                                                    content = new_content
                                                    fixed_count += 1
                                                    total_fixed += 1
                                                    
                                                    # è®°å½•è§£ç ä¿®å¤æ“ä½œ
                                                    fix_detail = {
                                                        "type": "decoded_exact_match",
                                                        "original_path": invalid_path,
                                                        "decoded_path": decoded_path,
                                                        "new_path": rel_correct_path,
                                                        "absolute_path": correct_path,
                                                        "confidence": "high"
                                                    }
                                                    file_record["fixes"].append(fix_detail)
                                                    
                                                    self.log(f"  âœ… è§£ç ä¿®å¤: {invalid_path} -> {rel_correct_path}")
                                                    break
                                        
                                        elif len(candidates) > 1:
                                            # å¤šä¸ªå€™é€‰ï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„è·¯å¾„
                                            best_match = self.find_best_path_match(decoded_path, candidates)
                                            if best_match:
                                                rel_best_path = self.safe_relpath(best_match, os.path.dirname(md_file))
                                                
                                                # æ›¿æ¢å†…å®¹ä¸­çš„è·¯å¾„
                                                old_patterns = [
                                                    f'!\\[([^\\]]*)\\]\\({re.escape(invalid_path)}\\)',
                                                    f'<img([^>]+)src=["\']{re.escape(invalid_path)}["\'](.*?)>',
                                                ]
                                                
                                                for pattern in old_patterns:
                                                    if '!\\[' in pattern:
                                                        new_content = re.sub(pattern, f'![\\1]({rel_best_path})', content)
                                                    else:
                                                        new_content = re.sub(pattern, f'<img\\1src="{rel_best_path}"\\2>', content)
                                                    
                                                    if new_content != content:
                                                        content = new_content
                                                        fixed_count += 1
                                                        total_fixed += 1
                                                        
                                                        # è®°å½•è§£ç æ™ºèƒ½åŒ¹é…æ“ä½œ
                                                        similarity_score = self.calculate_similarity(decoded_path, best_match)
                                                        fix_detail = {
                                                            "type": "decoded_smart_match",
                                                            "original_path": invalid_path,
                                                            "decoded_path": decoded_path,
                                                            "new_path": rel_best_path,
                                                            "absolute_path": best_match,
                                                            "confidence": "medium" if similarity_score > 0.7 else "low",
                                                            "similarity_score": similarity_score,
                                                            "candidates_count": len(candidates)
                                                        }
                                                        file_record["fixes"].append(fix_detail)
                                                        
                                                        self.log(f"  âœ… è§£ç æ™ºèƒ½åŒ¹é…: {invalid_path} -> {rel_best_path} (ç›¸ä¼¼åº¦: {similarity_score:.2f})")
                                                        break
                                    
                                    else:
                                        # è§£ç åçš„æ–‡ä»¶åä¹Ÿæ‰¾ä¸åˆ°ï¼Œå°è¯•å®Œæ•´è·¯å¾„åŒ¹é…
                                        decoded_match = self.find_decoded_path_match(decoded_path, self.image_files)
                                        if decoded_match:
                                            rel_decoded_path = self.safe_relpath(decoded_match, os.path.dirname(md_file))
                                            
                                            # æ›¿æ¢å†…å®¹ä¸­çš„è·¯å¾„
                                            old_patterns = [
                                                f'!\\[([^\\]]*)\\]\\({re.escape(invalid_path)}\\)',
                                                f'<img([^>]+)src=["\']{re.escape(invalid_path)}["\'](.*?)>',
                                            ]
                                            
                                            for pattern in old_patterns:
                                                if '!\\[' in pattern:
                                                    new_content = re.sub(pattern, f'![\\1]({rel_decoded_path})', content)
                                                else:
                                                    new_content = re.sub(pattern, f'<img\\1src="{rel_decoded_path}"\\2>', content)
                                                
                                                if new_content != content:
                                                    content = new_content
                                                    fixed_count += 1
                                                    total_fixed += 1
                                                    
                                                    # è®°å½•è§£ç è·¯å¾„åŒ¹é…æ“ä½œ
                                                    fix_detail = {
                                                        "type": "decoded_path_match",
                                                        "original_path": invalid_path,
                                                        "decoded_path": decoded_path,
                                                        "new_path": rel_decoded_path,
                                                        "absolute_path": decoded_match,
                                                        "confidence": "medium"
                                                    }
                                                    file_record["fixes"].append(fix_detail)
                                                    
                                                    self.log(f"  âœ… è§£ç è·¯å¾„åŒ¹é…: {invalid_path} -> {rel_decoded_path}")
                                                    break
                                
                                # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
                                if invalid_path in [fix["original_path"] for fix in file_record["fixes"]]:
                                    # å·²ç»ä¿®å¤è¿‡äº†ï¼Œè·³è¿‡
                                    pass
                                else:
                                    self.log(f"  âŒ æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {invalid_path}")
                                    if decoded_path != invalid_path:
                                        self.log(f"      è§£ç è·¯å¾„: {decoded_path}")
                        
                        # ä¿å­˜ä¿®æ”¹åçš„æ–‡ä»¶
                        if content != original_content:
                            with open(md_file, 'w', encoding='utf-8') as f:
                                f.write(content)
                            self.log(f"  ğŸ’¾ å·²ä¿å­˜ï¼Œä¿®å¤äº† {fixed_count} ä¸ªå¼•ç”¨")
                            fix_records["total_files_processed"] += 1
                        
                        # æ·»åŠ æ–‡ä»¶è®°å½•åˆ°æ€»è®°å½•ä¸­
                        if file_record["fixes"]:
                            fix_records["modifications"].append(file_record)
                    
                    except Exception as e:
                        self.log(f"âŒ å¤„ç†æ–‡ä»¶ {rel_md} æ—¶å‡ºé”™: {e}")
                        # è®°å½•é”™è¯¯
                        file_record["error"] = str(e)
                        fix_records["modifications"].append(file_record)
                
                # ä¿å­˜ä¿®å¤è®°å½•
                fix_records["total_fixes"] = total_fixed
                with open(fix_log_file, 'w', encoding='utf-8') as f:
                    json.dump(fix_records, f, ensure_ascii=False, indent=2)
                
                # ç”Ÿæˆæ’¤é”€è„šæœ¬
                self.generate_undo_script(backup_dir, fix_records)
                
                self.log(f"\næ™ºèƒ½ä¿®å¤å®Œæˆ!")
                self.log(f"æ€»è®¡å¤„ç†: {total_invalid} ä¸ªæ— æ•ˆå¼•ç”¨")
                self.log(f"æˆåŠŸä¿®å¤: {total_fixed} ä¸ªå¼•ç”¨")
                self.log(f"ä¿®å¤ç‡: {total_fixed/total_invalid*100:.1f}%")
                self.log(f"å¤‡ä»½ç›®å½•: {backup_dir}")
                self.log(f"ä¿®å¤è®°å½•: {fix_log_file}")
                
                if total_fixed > 0:
                    self.log("âœ… æ‰€æœ‰ä¿®æ”¹å·²è®°å½•ï¼Œå¯ä»¥æ’¤é”€")
                    self.log("å»ºè®®é‡æ–°æ‰«æä»¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")
                
            except Exception as e:
                self.log(f"æ™ºèƒ½ä¿®å¤å¤±è´¥: {e}")
        
        threading.Thread(target=fix_thread, daemon=True).start()
    
    def find_best_path_match(self, invalid_path, candidates):
        """æ‰¾åˆ°æœ€åŒ¹é…çš„è·¯å¾„ - ä¸¥æ ¼åŒ¹é…æ ‡å‡†"""
        import difflib
        
        # æå–æ— æ•ˆè·¯å¾„çš„ç›®å½•ç»“æ„å’Œæ–‡ä»¶å
        invalid_parts = invalid_path.replace('\\', '/').split('/')
        invalid_filename = os.path.basename(invalid_path).lower()
        
        best_score = 0
        best_match = None
        
        for candidate in candidates:
            candidate_parts = candidate.replace('\\', '/').split('/')
            candidate_filename = os.path.basename(candidate).lower()
            
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶åç›¸ä¼¼åº¦
            filename_similarity = difflib.SequenceMatcher(None, invalid_filename, candidate_filename).ratio()
            
            # åªæœ‰æ–‡ä»¶åç›¸ä¼¼åº¦å¾ˆé«˜æ‰è€ƒè™‘è·¯å¾„åŒ¹é…
            if filename_similarity < 0.95:  # æ–‡ä»¶åå¿…é¡»95%ç›¸ä¼¼
                continue
            
            # è®¡ç®—å®Œæ•´è·¯å¾„ç›¸ä¼¼åº¦
            path_similarity = difflib.SequenceMatcher(None, invalid_parts, candidate_parts).ratio()
            
            # ç»¼åˆè¯„åˆ†ï¼šæ–‡ä»¶åç›¸ä¼¼åº¦ * 0.8 + è·¯å¾„ç›¸ä¼¼åº¦ * 0.2
            combined_score = filename_similarity * 0.8 + path_similarity * 0.2
            
            if combined_score > best_score:
                best_score = combined_score
                best_match = candidate
        
        # åªæœ‰ç»¼åˆç›¸ä¼¼åº¦è¶…è¿‡0.9æ‰è®¤ä¸ºæ˜¯æœ‰æ•ˆåŒ¹é…
        return best_match if best_score > 0.9 else None
    
    def find_decoded_path_match(self, decoded_path, image_files):
        """é€šè¿‡è§£ç åçš„è·¯å¾„æŸ¥æ‰¾åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶ - ä¸¥æ ¼åŒ¹é…"""
        import difflib
        
        # æ ‡å‡†åŒ–è§£ç åçš„è·¯å¾„
        decoded_normalized = decoded_path.replace('\\', '/').lower()
        decoded_filename = os.path.basename(decoded_normalized)
        
        # é¦–å…ˆå°è¯•ç²¾ç¡®çš„æ–‡ä»¶ååŒ¹é…
        for img_file in image_files:
            img_normalized = img_file.replace('\\', '/').lower()
            img_filename = os.path.basename(img_normalized)
            
            # ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
            if decoded_filename == img_filename:
                return img_file
        
        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•è·¯å¾„åŒ…å«åŒ¹é…ï¼ˆä½†è¦æ±‚å¾ˆé«˜çš„ç›¸ä¼¼åº¦ï¼‰
        best_score = 0
        best_match = None
        
        for img_file in image_files:
            img_normalized = img_file.replace('\\', '/').lower()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œå…¨è·¯å¾„åŒ¹é…
            if decoded_normalized == img_normalized:
                return img_file
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«å…³ç³»ï¼ˆä¸¥æ ¼ï¼‰
            if decoded_normalized in img_normalized or img_normalized.endswith(decoded_normalized):
                # ä½†è¦æ±‚è·¯å¾„é•¿åº¦ç›¸è¿‘ï¼Œé¿å…è¯¯åŒ¹é…
                length_ratio = min(len(decoded_normalized), len(img_normalized)) / max(len(decoded_normalized), len(img_normalized))
                if length_ratio > 0.8:  # è·¯å¾„é•¿åº¦ç›¸ä¼¼åº¦è¦æ±‚80%ä»¥ä¸Š
                    return img_file
            
            # è®¡ç®—æ–‡ä»¶åç›¸ä¼¼åº¦ï¼ˆåªæœ‰æ–‡ä»¶åç›¸ä¼¼åº¦å¾ˆé«˜æ‰è€ƒè™‘ï¼‰
            decoded_filename = os.path.basename(decoded_normalized)
            img_filename = os.path.basename(img_normalized)
            filename_similarity = difflib.SequenceMatcher(None, decoded_filename, img_filename).ratio()
            
            # åªæœ‰æ–‡ä»¶åç›¸ä¼¼åº¦è¶…è¿‡0.9æ‰è€ƒè™‘ï¼ˆå‡ ä¹å®Œå…¨ç›¸åŒï¼‰
            if filename_similarity > 0.9 and filename_similarity > best_score:
                best_score = filename_similarity
                best_match = img_file
        
        # åªè¿”å›æ–‡ä»¶åå‡ ä¹å®Œå…¨ç›¸åŒçš„åŒ¹é…
        return best_match if best_score > 0.9 else None
    
    def calculate_similarity(self, path1, path2):
        """è®¡ç®—ä¸¤ä¸ªè·¯å¾„çš„ç›¸ä¼¼åº¦"""
        import difflib
        parts1 = path1.replace('\\', '/').split('/')
        parts2 = path2.replace('\\', '/').split('/')
        return difflib.SequenceMatcher(None, parts1, parts2).ratio()
    
    def generate_undo_script(self, backup_dir, fix_records):
        """ç”Ÿæˆæ’¤é”€è„šæœ¬"""
        undo_script = os.path.join(backup_dir, "undo_fixes.py")
        
        # é¿å…å˜é‡åå†²çªï¼Œå¹¶ç»Ÿä¸€è·¯å¾„æ ¼å¼
        backup_dir_path = backup_dir.replace('\\', '/')
        workspace_path = self.workspace_path.replace('\\', '/')
        
        script_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½ä¿®å¤æ’¤é”€è„šæœ¬
ç”Ÿæˆæ—¶é—´: {fix_records["timestamp"]}
ä¿®å¤æ–‡ä»¶æ•°: {fix_records["total_files_processed"]}
ä¿®å¤å¼•ç”¨æ•°: {fix_records["total_fixes"]}
"""

import os
import shutil
import json

def undo_fixes():
    backup_dir = r"{backup_dir_path}"
    
    print("å¼€å§‹æ’¤é”€æ™ºèƒ½ä¿®å¤æ“ä½œ...")
    
    # è¯»å–ä¿®å¤è®°å½•
    with open(os.path.join(backup_dir, "fix_log.json"), 'r', encoding='utf-8') as f:
        records = json.load(f)
    
    restored_count = 0
    
    for mod in records["modifications"]:
        try:
            backup_file = mod["backup_file"]
            original_file = mod["file"]
            
            if os.path.exists(backup_file):
                # æ¢å¤åŸå§‹æ–‡ä»¶
                workspace_path = r"{workspace_path}"
                target_file = os.path.join(workspace_path, original_file)
                
                shutil.copy2(backup_file, target_file)
                restored_count += 1
                print(f"âœ… å·²æ¢å¤: {{original_file}}")
            else:
                print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {{backup_file}}")
        
        except Exception as e:
            print(f"âŒ æ¢å¤å¤±è´¥ {{mod['file']}}: {{e}}")
    
    print(f"\\næ’¤é”€å®Œæˆ! å…±æ¢å¤ {{restored_count}} ä¸ªæ–‡ä»¶")
    print("å»ºè®®é‡æ–°æ‰«æä»¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")

if __name__ == "__main__":
    undo_fixes()
'''
        
        with open(undo_script, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        self.log(f"ç”Ÿæˆæ’¤é”€è„šæœ¬: {undo_script}")
        self.log("å¦‚éœ€æ’¤é”€ä¿®æ”¹ï¼Œè¿è¡Œ: python undo_fixes.py")
    
    def undo_fixes(self):
        """æ’¤é”€æœ€è¿‘çš„æ™ºèƒ½ä¿®å¤æ“ä½œ"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²é€‰æ‹©å·¥ä½œç›®å½•
            if not self.workspace_path:
                messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å·¥ä½œç›®å½•")
                return
            
            # æŸ¥æ‰¾æœ€æ–°çš„å¤‡ä»½ç›®å½•
            backup_base = os.path.join(self.workspace_path, ".backup")
            if not os.path.exists(backup_base):
                messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½ç›®å½•ï¼Œæ— æ³•æ’¤é”€\n\nå¯èƒ½åŸå› ï¼š\n1. è¿˜æ²¡æœ‰æ‰§è¡Œè¿‡æ™ºèƒ½ä¿®å¤æ“ä½œ\n2. å¤‡ä»½ç›®å½•è¢«åˆ é™¤äº†")
                return
            
            # è·å–æ‰€æœ‰å¤‡ä»½ç›®å½•ï¼ŒæŒ‰æ—¶é—´æ’åº
            backup_dirs = []
            for item in os.listdir(backup_base):
                backup_path = os.path.join(backup_base, item)
                if os.path.isdir(backup_path) and item.startswith("smart_fix_"):
                    backup_dirs.append(backup_path)
            
            if not backup_dirs:
                messagebox.showinfo("ä¿¡æ¯", "æ²¡æœ‰æ‰¾åˆ°æ™ºèƒ½ä¿®å¤çš„å¤‡ä»½è®°å½•\n\nå¯èƒ½åŸå› ï¼š\n1. è¿˜æ²¡æœ‰æ‰§è¡Œè¿‡æ™ºèƒ½ä¿®å¤æ“ä½œ\n2. å¤‡ä»½è®°å½•è¢«åˆ é™¤äº†\n3. å¤‡ä»½ç›®å½•ä¸­æ²¡æœ‰ä»¥'smart_fix_'å¼€å¤´çš„ç›®å½•")
                return
            
            # é€‰æ‹©æœ€æ–°çš„å¤‡ä»½
            latest_backup = max(backup_dirs, key=os.path.getctime)
            fix_log_file = os.path.join(latest_backup, "fix_log.json")
            
            if not os.path.exists(fix_log_file):
                messagebox.showerror("é”™è¯¯", "å¤‡ä»½è®°å½•æ–‡ä»¶ä¸å­˜åœ¨")
                return
            
            # ç¡®è®¤æ’¤é”€æ“ä½œ
            result = messagebox.askyesno(
                "ç¡®è®¤æ’¤é”€", 
                f"ç¡®å®šè¦æ’¤é”€æœ€è¿‘çš„æ™ºèƒ½ä¿®å¤æ“ä½œå—ï¼Ÿ\nå¤‡ä»½ç›®å½•: {os.path.basename(latest_backup)}"
            )
            
            if not result:
                return
            
            # è¯»å–ä¿®å¤è®°å½•
            with open(fix_log_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
            
            self.log("å¼€å§‹æ’¤é”€æ™ºèƒ½ä¿®å¤æ“ä½œ...")
            restored_count = 0
            
            for mod in records["modifications"]:
                try:
                    backup_file = mod["backup_file"]
                    original_file = mod["file"]
                    
                    if os.path.exists(backup_file):
                        # æ¢å¤åŸå§‹æ–‡ä»¶
                        target_file = os.path.join(self.workspace_path, original_file)
                        shutil.copy2(backup_file, target_file)
                        restored_count += 1
                        self.log(f"âœ… å·²æ¢å¤: {original_file}")
                    else:
                        self.log(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
                
                except Exception as e:
                    self.log(f"âŒ æ¢å¤å¤±è´¥ {mod['file']}: {e}")
            
            self.log(f"\næ’¤é”€å®Œæˆ! å…±æ¢å¤ {restored_count} ä¸ªæ–‡ä»¶")
            self.log("å»ºè®®é‡æ–°æ‰«æä»¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")
            
            messagebox.showinfo("å®Œæˆ", f"æ’¤é”€å®Œæˆ!\nå…±æ¢å¤ {restored_count} ä¸ªæ–‡ä»¶\nå»ºè®®é‡æ–°æ‰«æä»¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")
            
        except Exception as e:
            self.log(f"æ’¤é”€æ“ä½œå¤±è´¥: {e}")
            messagebox.showerror("é”™è¯¯", f"æ’¤é”€æ“ä½œå¤±è´¥: {e}")
    
    def export_report(self):
        """å¯¼å‡ºåˆ†ææŠ¥å‘Š"""
        if not self.md_files:
            messagebox.showinfo("ä¿¡æ¯", "è¯·å…ˆæ‰«æåˆ†ææ–‡ä»¶")
            return
        
        try:
            report_file = os.path.join(self.workspace_path, "markdown_image_report.md")
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("# Markdownå›¾ç‰‡ç®¡ç†æŠ¥å‘Š\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {os.path.basename(__file__)}\n")
                f.write(f"å·¥ä½œç›®å½•: {self.workspace_path}\n\n")
                
                # ç»Ÿè®¡ä¿¡æ¯
                referenced_local_count = len(getattr(self, 'referenced_local_images', []))
                unused_count = len(self.image_files) - referenced_local_count if referenced_local_count > 0 else len(self.unused_images)
                
                f.write("## ç»Ÿè®¡ä¿¡æ¯\n\n")
                f.write(f"- MDæ–‡ä»¶æ€»æ•°: {len(self.md_files)}\n")
                f.write(f"- æœ¬åœ°å›¾ç‰‡æ–‡ä»¶æ€»æ•°: {len(self.image_files)}\n")
                f.write(f"- è¢«å¼•ç”¨çš„æœ¬åœ°å›¾ç‰‡æ•°: {referenced_local_count}\n")
                f.write(f"- è¢«å¼•ç”¨çš„è¿œç¨‹å›¾ç‰‡æ•°: {len(getattr(self, 'remote_images', []))}\n")
                f.write(f"- æœªè¢«å¼•ç”¨çš„æœ¬åœ°å›¾ç‰‡æ•°: {unused_count}\n")
                f.write(f"- æ— æ•ˆå¼•ç”¨æ•°: {sum(len(imgs) for imgs in self.invalid_images.values())}\n")
                f.write(f"- å›¾ç‰‡æ˜ å°„è®°å½•æ•°: {len(self.image_mapping)}\n\n")
                
                # MDæ–‡ä»¶å›¾ç‰‡å¼•ç”¨
                f.write("## MDæ–‡ä»¶å›¾ç‰‡å¼•ç”¨\n\n")
                for md_file, images in self.image_references.items():
                    rel_md = self.safe_relpath(md_file, self.workspace_path)
                    f.write(f"### {rel_md}\n\n")
                    for img in images:
                        if img.startswith('http'):
                            f.write(f"- ğŸŒ {img}\n")
                        else:
                            rel_img = self.safe_relpath(img, self.workspace_path)
                            f.write(f"- ğŸ–¼ï¸ {rel_img}\n")
                    f.write("\n")
                
                # æ— æ•ˆå›¾ç‰‡å¼•ç”¨
                if self.invalid_images:
                    f.write("## æ— æ•ˆå›¾ç‰‡å¼•ç”¨\n\n")
                    for md_file, invalid_imgs in self.invalid_images.items():
                        rel_md = self.safe_relpath(md_file, self.workspace_path)
                        f.write(f"### {rel_md}\n\n")
                        for img in invalid_imgs:
                            f.write(f"- âŒ {img}\n")
                        f.write("\n")
                
                # æœªè¢«å¼•ç”¨çš„å›¾ç‰‡
                if self.unused_images:
                    f.write("## æœªè¢«å¼•ç”¨çš„å›¾ç‰‡\n\n")
                    for img in self.unused_images:
                        rel_img = self.safe_relpath(img, self.workspace_path)
                        f.write(f"- ğŸ—‘ï¸ {rel_img}\n")
                    f.write("\n")
                
                # å›¾ç‰‡æ˜ å°„è¡¨
                if self.image_mapping:
                    f.write("## å›¾ç‰‡æ˜ å°„è¡¨\n\n")
                    for local_path, remote_url in self.image_mapping.items():
                        rel_local = self.safe_relpath(local_path, self.workspace_path)
                        f.write(f"- **æœ¬åœ°**: {rel_local}\n")
                        f.write(f"  **è¿œç¨‹**: {remote_url}\n\n")
            
            self.log(f"æŠ¥å‘Šå·²å¯¼å‡º: {report_file}")
            messagebox.showinfo("æˆåŠŸ", f"æŠ¥å‘Šå·²å¯¼å‡ºåˆ°:\n{report_file}")
            
        except Exception as e:
            self.log(f"å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        self.root.mainloop()

if __name__ == "__main__":
    app = MarkdownImageManager()
    app.run()